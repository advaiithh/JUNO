<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>JUNO - AI Voice Assistant</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, sans-serif;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            min-height: 100vh;
            display: flex;
            justify-content: center;
            align-items: center;
            padding: 20px;
        }

        .container {
            background: white;
            border-radius: 20px;
            box-shadow: 0 20px 60px rgba(0, 0, 0, 0.3);
            padding: 40px;
            max-width: 500px;
            width: 100%;
            text-align: center;
        }

        .logo {
            font-size: 48px;
            margin-bottom: 10px;
        }

        h1 {
            color: #333;
            margin-bottom: 10px;
            font-size: 32px;
        }

        .subtitle {
            color: #666;
            margin-bottom: 30px;
            font-size: 16px;
        }

        .status {
            background: #f3f4f6;
            border-radius: 10px;
            padding: 15px;
            margin-bottom: 30px;
            font-size: 14px;
            color: #666;
        }

        .status.active {
            background: #d1fae5;
            color: #065f46;
        }

        .status.recording {
            background: #fee2e2;
            color: #991b1b;
        }

        .status.processing {
            background: #fef3c7;
            color: #92400e;
        }

        .status.error {
            background: #fee2e2;
            color: #991b1b;
        }

        .mic-button {
            width: 120px;
            height: 120px;
            border-radius: 50%;
            border: none;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            font-size: 48px;
            cursor: pointer;
            transition: all 0.3s;
            margin: 20px auto;
            display: flex;
            align-items: center;
            justify-content: center;
            box-shadow: 0 10px 30px rgba(102, 126, 234, 0.4);
        }

        .mic-button:hover {
            transform: scale(1.05);
            box-shadow: 0 15px 40px rgba(102, 126, 234, 0.5);
        }

        .mic-button:active {
            transform: scale(0.95);
        }

        .mic-button.recording {
            background: #ef4444;
            animation: pulse 1.5s infinite;
        }

        .mic-button.processing {
            background: #f59e0b;
        }

        @keyframes pulse {
            0%, 100% { transform: scale(1); }
            50% { transform: scale(1.1); }
        }

        .transcript-box {
            background: #f9fafb;
            border-radius: 10px;
            padding: 15px;
            margin: 20px 0;
            min-height: 60px;
            text-align: left;
            display: none;
        }

        .transcript-box.active {
            display: block;
        }

        .transcript-label {
            font-size: 12px;
            color: #666;
            margin-bottom: 5px;
        }

        .transcript-text {
            color: #333;
            font-size: 14px;
        }

        .response-box {
            background: #eff6ff;
            border-radius: 10px;
            padding: 15px;
            margin: 20px 0;
            min-height: 60px;
            text-align: left;
            display: none;
        }

        .response-box.active {
            display: block;
        }

        .response-label {
            font-size: 12px;
            color: #1e40af;
            margin-bottom: 5px;
            font-weight: 600;
        }

        .response-text {
            color: #1e3a8a;
            font-size: 14px;
            line-height: 1.6;
        }

        .error-box {
            background: #fee2e2;
            border-radius: 10px;
            padding: 15px;
            margin: 20px 0;
            color: #991b1b;
            font-size: 14px;
            display: none;
        }

        .error-box.active {
            display: block;
        }

        .fix-button {
            background: #667eea;
            color: white;
            border: none;
            border-radius: 8px;
            padding: 10px 20px;
            margin-top: 10px;
            cursor: pointer;
            font-size: 14px;
            font-weight: 600;
            transition: all 0.3s;
        }

        .fix-button:hover {
            background: #5568d3;
            transform: translateY(-2px);
        }

        .permission-help {
            background: #eff6ff;
            border-radius: 10px;
            padding: 20px;
            margin: 20px 0;
            display: none;
        }

        .permission-help.active {
            display: block;
        }

        .permission-help h3 {
            color: #1e40af;
            margin-bottom: 10px;
            font-size: 16px;
        }

        .permission-help ol {
            color: #1e3a8a;
            margin-left: 20px;
            line-height: 1.8;
        }

        .permission-help li {
            margin-bottom: 8px;
        }

        .instructions {
            color: #666;
            font-size: 14px;
            margin-top: 20px;
        }
    </style>
</head>
<body>
    <div class="container">
        <div class="logo">ü§ñ</div>
        <h1>JUNO</h1>
        <div class="subtitle">AI Voice Assistant</div>
        
        <div class="status" id="status">Checking server...</div>
        
        <button class="mic-button" id="micButton">
            üé§
        </button>
        
        <div class="instructions" id="instructions">Click the microphone to start</div>
        
        <div class="transcript-box" id="transcriptBox">
            <div class="transcript-label">You said:</div>
            <div class="transcript-text" id="transcriptText"></div>
        </div>
        
        <div class="response-box" id="responseBox">
            <div class="response-label">JUNO:</div>
            <div class="response-text" id="responseText"></div>
        </div>
        
        <div class="error-box" id="errorBox"></div>
        
        <div class="permission-help" id="permissionHelp">
            <h3>üîß How to Fix Microphone Permission:</h3>
            <ol>
                <li><strong>Click the lock icon</strong> üîí in your browser's address bar</li>
                <li>Find <strong>"Microphone"</strong> in the dropdown</li>
                <li>Change it to <strong>"Allow"</strong></li>
                <li><strong>Refresh this page</strong> (Press F5)</li>
                <li>Click the microphone button again</li>
            </ol>
            <button class="fix-button" onclick="window.location.reload()">üîÑ Refresh Page</button>
        </div>
    </div>

    <script>
        // State
        let mediaRecorder = null;
        let audioChunks = [];
        let isRecording = false;
        let audioStream = null;
        let isSpeaking = false;
        let interruptionListener = null;
        let audioContext = null;
        let analyser = null;
        let microphone = null;
        let silenceTimer = null;
        let wakeWordMode = false; // After response, wait for wake word
        let silenceDetectionContext = null;
        let silenceAnalyser = null;
        const SILENCE_TIMEOUT = 5000; // 5 seconds
        const SILENCE_THRESHOLD = 20; // Volume threshold for silence

        // Elements
        const micButton = document.getElementById('micButton');
        const statusDiv = document.getElementById('status');
        const instructionsDiv = document.getElementById('instructions');
        const transcriptBox = document.getElementById('transcriptBox');
        const transcriptText = document.getElementById('transcriptText');
        const responseBox = document.getElementById('responseBox');
        const responseText = document.getElementById('responseText');
        const errorBox = document.getElementById('errorBox');

        // Update status
        function updateStatus(message, className = '') {
            statusDiv.textContent = message;
            statusDiv.className = 'status ' + className;
            console.log('Status:', message);
        }

        // Show error
        function showError(message) {
            errorBox.textContent = message;
            errorBox.classList.add('active');
            console.error('Error:', message);
            
            // Show permission help if it's a permission error
            if (message.includes('permission') || message.includes('Permission')) {
                document.getElementById('permissionHelp').classList.add('active');
            }
        }

        // Hide error
        function hideError() {
            errorBox.classList.remove('active');
        }

        // Check server status
        async function checkServer() {
            try {
                const response = await fetch('/status');
                if (response.ok) {
                    const data = await response.json();
                    console.log('Server status:', data);
                    if (data.status === 'running') {
                        updateStatus('‚úÖ Ready to listen', 'active');
                        if (!data.stt_available) {
                            showError('STT not available. Voice features disabled.');
                        }
                        return true;
                    }
                }
                updateStatus('‚ö†Ô∏è Server not ready', 'error');
                return false;
            } catch (error) {
                console.error('Server check failed:', error);
                updateStatus('‚ùå Cannot connect to server', 'error');
                showError('Cannot connect to server. Make sure it\'s running.');
                return false;
            }
        }

        // Start silence detection
        function startSilenceDetection() {
            if (!audioStream || !isRecording) return;
            
            try {
                silenceDetectionContext = new (window.AudioContext || window.webkitAudioContext)();
                silenceAnalyser = silenceDetectionContext.createAnalyser();
                const source = silenceDetectionContext.createMediaStreamSource(audioStream);
                source.connect(silenceAnalyser);
                
                silenceAnalyser.fftSize = 256;
                const bufferLength = silenceAnalyser.frequencyBinCount;
                const dataArray = new Uint8Array(bufferLength);
                
                let lastSoundTime = Date.now();
                
                function checkSilence() {
                    if (!isRecording) {
                        stopSilenceDetection();
                        return;
                    }
                    
                    silenceAnalyser.getByteFrequencyData(dataArray);
                    
                    // Calculate average volume
                    let sum = 0;
                    for (let i = 0; i < bufferLength; i++) {
                        sum += dataArray[i];
                    }
                    const average = sum / bufferLength;
                    
                    // Check if sound detected
                    if (average > SILENCE_THRESHOLD) {
                        lastSoundTime = Date.now();
                        // Clear any existing timer
                        if (silenceTimer) {
                            clearTimeout(silenceTimer);
                            silenceTimer = null;
                        }
                    } else {
                        // Check if silence has been too long
                        const silenceDuration = Date.now() - lastSoundTime;
                        if (silenceDuration >= SILENCE_TIMEOUT && !silenceTimer) {
                            console.log('5 seconds of silence detected - stopping recording');
                            stopRecording();
                            return;
                        }
                    }
                    
                    if (isRecording) {
                        requestAnimationFrame(checkSilence);
                    }
                }
                
                checkSilence();
            } catch (error) {
                console.log('Silence detection not available:', error);
            }
        }

        // Stop silence detection
        function stopSilenceDetection() {
            if (silenceTimer) {
                clearTimeout(silenceTimer);
                silenceTimer = null;
            }
            if (silenceDetectionContext && silenceDetectionContext.state !== 'closed') {
                silenceDetectionContext.close();
                silenceDetectionContext = null;
            }
            silenceAnalyser = null;
        }

        // Check for wake word - simplified to "talk to me"
        function checkWakeWord(text) {
            const textLower = text.toLowerCase().trim();
            return textLower.includes('talk to me');
        }

        // Start recording
        async function startRecording() {
            try {
                hideError();
                updateStatus('üé§ Requesting microphone...', 'processing');
                
                // Request microphone
                audioStream = await navigator.mediaDevices.getUserMedia({ 
                    audio: {
                        echoCancellation: true,
                        noiseSuppression: true
                    } 
                });
                
                console.log('Microphone access granted');
                updateStatus('üî¥ Recording...', 'recording');
                
                // Setup MediaRecorder
                const options = { mimeType: 'audio/webm' };
                if (!MediaRecorder.isTypeSupported(options.mimeType)) {
                    options.mimeType = '';
                }
                
                mediaRecorder = new MediaRecorder(audioStream, options);
                audioChunks = [];
                
                mediaRecorder.ondataavailable = (event) => {
                    if (event.data.size > 0) {
                        audioChunks.push(event.data);
                    }
                };
                
                mediaRecorder.onstop = async () => {
                    console.log('Recording stopped, chunks:', audioChunks.length);
                    stopSilenceDetection();
                    
                    if (audioChunks.length > 0) {
                        const blob = new Blob(audioChunks, { type: mediaRecorder.mimeType || 'audio/webm' });
                        await sendToServer(blob);
                    } else {
                        updateStatus('‚ùå No audio recorded', 'error');
                        showError('No audio was recorded. Please try again.');
                        resetUI();
                    }
                };
                
                // Start recording
                mediaRecorder.start(100);
                isRecording = true;
                
                // Start silence detection
                startSilenceDetection();
                
                // Update UI
                micButton.classList.add('recording');
                micButton.textContent = '‚èπÔ∏è';
                instructionsDiv.textContent = 'Click to stop or wait 5s of silence';
                
            } catch (error) {
                console.error('Recording error:', error);
                let errorMsg = 'Microphone error: ';
                
                if (error.name === 'NotAllowedError' || error.name === 'PermissionDeniedError') {
                    errorMsg = 'Microphone permission denied. Click the lock icon üîí in the address bar and allow microphone access, then refresh the page.';
                } else if (error.name === 'NotFoundError' || error.name === 'DevicesNotFoundError') {
                    errorMsg = 'No microphone found. Please connect a microphone and try again.';
                } else if (error.name === 'NotReadableError' || error.name === 'TrackStartError') {
                    errorMsg = 'Microphone is being used by another application. Please close other apps using the microphone.';
                } else {
                    errorMsg += error.message;
                }
                
                showError(errorMsg);
                updateStatus('‚ùå Microphone error', 'error');
                resetUI();
            }
        }

        // Stop recording
        function stopRecording() {
            if (mediaRecorder && isRecording) {
                stopSilenceDetection();
                mediaRecorder.stop();
                if (audioStream) {
                    audioStream.getTracks().forEach(track => track.stop());
                }
                isRecording = false;
                
                updateStatus('‚è≥ Processing...', 'processing');
                micButton.classList.remove('recording');
                micButton.classList.add('processing');
                micButton.textContent = '‚è≥';
                instructionsDiv.textContent = 'Processing your request...';
            }
        }

        // Send audio to server
        async function sendToServer(audioBlob) {
            try {
                console.log('Sending audio to server, size:', audioBlob.size);
                updateStatus('üì§ Sending to server...', 'processing');
                
                const formData = new FormData();
                const extension = audioBlob.type.includes('webm') ? 'webm' : 'wav';
                formData.append('file', audioBlob, `recording.${extension}`);
                
                const response = await fetch('/voice_chat', {
                    method: 'POST',
                    body: formData
                });
                
                console.log('Response status:', response.status);
                
                if (!response.ok) {
                    const errorText = await response.text();
                    throw new Error(`Server error: ${response.status} - ${errorText}`);
                }
                
                const result = await response.json();
                console.log('Server response:', result);
                
                // Handle errors
                if (result.error) {
                    throw new Error(result.error);
                }
                
                // Show transcript
                if (result.transcript) {
                    transcriptText.textContent = result.transcript;
                    transcriptBox.classList.add('active');
                }
                
                // Check for wake word
                const transcriptLower = result.transcript.toLowerCase();
                const isWakeWord = checkWakeWord(result.transcript);
                
                if (isWakeWord && wakeWordMode) {
                    // Wake word detected - exit wake word mode
                    wakeWordMode = false;
                    updateStatus('‚úÖ Ready to listen', 'active');
                    instructionsDiv.textContent = 'Click the microphone to start';
                    return;
                }
                
                // Show response
                if (result.response) {
                    responseText.textContent = result.response;
                    responseBox.classList.add('active');
                    
                    // Check if it's a music-related query (English and Malayalam)
                    const isMusicQuery = transcriptLower.includes('song') || 
                                        transcriptLower.includes('music') || 
                                        transcriptLower.includes('sing') ||
                                        transcriptLower.includes('play') ||
                                        result.transcript.includes('‡¥™‡¥æ‡¥ü‡µç‡¥ü‡µç') ||
                                        result.transcript.includes('‡¥ó‡¥æ‡¥®‡¥Ç') ||
                                        result.transcript.includes('‡¥∏‡¥Ç‡¥ó‡µÄ‡¥§‡¥Ç');
                    
                    if (isMusicQuery) {
                        // For music queries, provide search link
                        const searchQuery = encodeURIComponent(result.transcript);
                        const searchLink = `https://www.google.com/search?q=${searchQuery}+song`;
                        responseText.innerHTML = result.response + 
                            `<br><br><a href="${searchLink}" target="_blank" style="color: #667eea; text-decoration: underline; font-weight: 600;">üîç Search for this song on Google</a>`;
                    }
                    
                    // Play audio response using browser's built-in TTS
                    speakText(result.response);
                    
                    // After response, enter wake word mode
                    wakeWordMode = true;
                } else {
                    throw new Error('No response received from server');
                }
                
                updateStatus('‚úÖ Waiting for wake word...', 'active');
                instructionsDiv.textContent = 'Say "talk to me" or click mic to continue';
                resetUI();
                
            } catch (error) {
                console.error('Send error:', error);
                showError('Error: ' + error.message);
                updateStatus('‚ùå Error occurred', 'error');
                resetUI();
            }
        }

        // Reset UI
        function resetUI() {
            micButton.classList.remove('recording', 'processing', 'speaking');
            micButton.textContent = 'üé§';
            if (!wakeWordMode) {
                instructionsDiv.textContent = 'Click the microphone to start';
            }
        }

        // Stop speaking
        function stopSpeaking() {
            if ('speechSynthesis' in window) {
                window.speechSynthesis.cancel();
                isSpeaking = false;
                stopInterruptionListener();
                updateStatus('‚úÖ Ready to listen', 'active');
                console.log('Speech stopped');
            }
        }

        // Start interruption listener (detects when user starts talking)
        function startInterruptionListener() {
            if (!navigator.mediaDevices || !navigator.mediaDevices.getUserMedia) {
                return;
            }

            navigator.mediaDevices.getUserMedia({ audio: true })
                .then(stream => {
                    audioContext = new (window.AudioContext || window.webkitAudioContext)();
                    analyser = audioContext.createAnalyser();
                    microphone = audioContext.createMediaStreamSource(stream);
                    microphone.connect(analyser);
                    
                    analyser.fftSize = 256;
                    const bufferLength = analyser.frequencyBinCount;
                    const dataArray = new Uint8Array(bufferLength);
                    
                    let silenceCount = 0;
                    const SILENCE_THRESHOLD = 30; // Adjust based on testing
                    const VOICE_THRESHOLD = 50; // Minimum to detect voice
                    const SILENCE_FRAMES = 5; // Frames of silence before considering it stopped
                    
                    function checkAudio() {
                        if (!isSpeaking) {
                            stopInterruptionListener();
                            return;
                        }
                        
                        analyser.getByteFrequencyData(dataArray);
                        
                        // Calculate average volume
                        let sum = 0;
                        for (let i = 0; i < bufferLength; i++) {
                            sum += dataArray[i];
                        }
                        const average = sum / bufferLength;
                        
                        // Detect voice activity
                        if (average > VOICE_THRESHOLD) {
                            silenceCount = 0;
                            // User is speaking - interrupt!
                            console.log('Voice detected during speech - interrupting!');
                            stopSpeaking();
                            setTimeout(() => startRecording(), 200);
                            stopInterruptionListener();
                        } else {
                            silenceCount++;
                        }
                        
                        if (isSpeaking) {
                            requestAnimationFrame(checkAudio);
                        }
                    }
                    
                    interruptionListener = stream;
                    checkAudio();
                })
                .catch(err => {
                    console.log('Interruption listener not available:', err);
                });
        }

        // Stop interruption listener
        function stopInterruptionListener() {
            if (interruptionListener) {
                interruptionListener.getTracks().forEach(track => track.stop());
                interruptionListener = null;
            }
            if (audioContext && audioContext.state !== 'closed') {
                audioContext.close();
                audioContext = null;
            }
            analyser = null;
            microphone = null;
        }

        // Text-to-Speech using browser's Web Speech API
        function speakText(text) {
            if ('speechSynthesis' in window) {
                // Stop any ongoing speech
                window.speechSynthesis.cancel();
                
                const utterance = new SpeechSynthesisUtterance(text);
                
                // Configure voice settings
                utterance.rate = 1.0;  // Normal speed
                utterance.pitch = 1.0; // Normal pitch
                utterance.volume = 1.0; // Full volume
                
                // Try to use a natural-sounding voice
                const voices = window.speechSynthesis.getVoices();
                const preferredVoices = ['Google UK English Female', 'Microsoft Zira', 'Samantha', 'Alex'];
                
                for (const preferred of preferredVoices) {
                    const voice = voices.find(v => v.name.includes(preferred));
                    if (voice) {
                        utterance.voice = voice;
                        break;
                    }
                }
                
                // If no preferred voice, use default
                if (!utterance.voice && voices.length > 0) {
                    utterance.voice = voices.find(v => v.lang.startsWith('en')) || voices[0];
                }
                
                utterance.onstart = () => {
                    console.log('Speaking:', text.substring(0, 50) + '...');
                    isSpeaking = true;
                    updateStatus('üîä Speaking... (click mic or speak to interrupt)', 'processing');
                    // Start listening for interruptions
                    startInterruptionListener();
                };
                
                utterance.onend = () => {
                    console.log('Finished speaking');
                    isSpeaking = false;
                    stopInterruptionListener();
                    
                    // After speaking, enter wake word mode
                    if (wakeWordMode) {
                        updateStatus('‚úÖ Waiting for wake word...', 'active');
                        instructionsDiv.textContent = 'Say "talk to me" or click mic to continue';
                    } else {
                        updateStatus('‚úÖ Ready to listen', 'active');
                    }
                };
                
                utterance.onerror = (error) => {
                    console.error('Speech error:', error);
                    isSpeaking = false;
                    stopInterruptionListener();
                    updateStatus('‚úÖ Ready to listen', 'active');
                };
                
                // Load voices if not already loaded
                if (voices.length === 0) {
                    window.speechSynthesis.onvoiceschanged = () => {
                        speakText(text); // Retry with loaded voices
                    };
                    return;
                }
                
                window.speechSynthesis.speak(utterance);
            } else {
                console.warn('Speech synthesis not supported in this browser');
            }
        }

        // Mic button click handler
        micButton.addEventListener('click', () => {
            console.log('Mic button clicked, isRecording:', isRecording, 'isSpeaking:', isSpeaking, 'wakeWordMode:', wakeWordMode);
            
            // If speaking, stop speech and start listening
            if (isSpeaking) {
                stopSpeaking();
                wakeWordMode = false; // Exit wake word mode
                setTimeout(() => startRecording(), 300); // Small delay for smooth transition
                return;
            }
            
            // If in wake word mode, exit it and start recording
            if (wakeWordMode) {
                wakeWordMode = false;
                startRecording();
                return;
            }
            
            // Normal recording toggle
            if (isRecording) {
                stopRecording();
            } else {
                startRecording();
            }
        });

        // Initialize
        console.log('JUNO UI Initializing...');
        checkServer();
        console.log('JUNO UI Ready');
    </script>
</body>
</html>
