"""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                                                                              â•‘
â•‘                    JUNO - COMPLETE AI VOICE ASSISTANT                        â•‘
â•‘                                                                              â•‘
â•‘  All-in-one voice assistant with:                                           â•‘
â•‘    âœ“ Real-time audio recording with Voice Activity Detection (VAD)          â•‘
â•‘    âœ“ Speech-to-Text (Whisper - fast & accurate)                             â•‘
â•‘    âœ“ AI conversation with memory (Ollama LLM)                               â•‘
â•‘    âœ“ Text-to-Speech (Piper - natural voice)                                 â•‘
â•‘    âœ“ Conversation memory persistence                                        â•‘
â•‘    âœ“ Smart command detection                                               â•‘
â•‘    âœ“ Zero latency optimizations                                             â•‘
â•‘                                                                              â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
"""

import os
import sys
import json
import time
import wave
import subprocess
import tempfile
from pathlib import Path
from datetime import datetime

# Audio processing
try:
    import pyaudio
    PYAUDIO_AVAILABLE = True
except ImportError:
    PYAUDIO_AVAILABLE = False
    print("âš  Warning: pyaudio not installed. Install: pip install pyaudio")

try:
    import numpy as np
    NUMPY_AVAILABLE = True
except ImportError:
    NUMPY_AVAILABLE = False
    print("âš  Warning: numpy not installed. Install: pip install numpy")

# AI Models
try:
    from faster_whisper import WhisperModel
    STT_AVAILABLE = True
except ImportError:
    STT_AVAILABLE = False
    print("âš  Warning: faster_whisper not installed. Install: pip install faster-whisper")

# Windows audio playback
try:
    import winsound
    AUDIO_PLAYBACK = True
except ImportError:
    AUDIO_PLAYBACK = False
    print("âš  Warning: winsound not available (Windows only)")

# HTTP for Ollama
try:
    import requests
    REQUESTS_AVAILABLE = True
except ImportError:
    REQUESTS_AVAILABLE = False
    print("âš  Warning: requests not installed. Install: pip install requests")


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#                          CONFIGURATION
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class Config:
    """Centralized configuration"""
    
    # Audio settings
    SAMPLE_RATE = 16000
    CHUNK_DURATION_MS = 30
    SILENCE_THRESHOLD_FRAMES = 8
    ENERGY_THRESHOLD = 300
    MIN_RECORDING_MS = 500
    MAX_RECORDING_SECONDS = 30
    
    # Paths
    PIPER_EXE = "piper/piper.exe"
    PIPER_VOICE = "piper/voices/en_US-lessac-medium.onnx"
    MEMORY_FILE = "conversation_memory.json"
    
    # LLM settings
    OLLAMA_URL = "http://localhost:11434/api/generate"
    OLLAMA_MODEL = "llama3.1:8b"
    MAX_HISTORY = 20
    MAX_TOKENS = 80
    
    # Whisper settings
    WHISPER_MODEL = "base"
    WHISPER_BEAM_SIZE = 5
    
    # Files
    TEMP_AUDIO = "temp_recording.wav"
    RESPONSE_AUDIO = "response.wav"


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#                       AUDIO RECORDER WITH VAD
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class AudioRecorder:
    """Real-time audio recording with energy-based Voice Activity Detection"""
    
    def __init__(self):
        if not PYAUDIO_AVAILABLE or not NUMPY_AVAILABLE:
            self.available = False
            return
        
        self.available = True
        self.sample_rate = Config.SAMPLE_RATE
        self.chunk_duration_ms = Config.CHUNK_DURATION_MS
        self.chunk_size = int(self.sample_rate * self.chunk_duration_ms / 1000)
        self.silence_threshold = Config.SILENCE_THRESHOLD_FRAMES
        self.energy_threshold = Config.ENERGY_THRESHOLD
        
    def _get_audio_energy(self, audio_chunk):
        """Calculate RMS energy of audio chunk"""
        if not NUMPY_AVAILABLE:
            return 0
        audio_data = np.frombuffer(audio_chunk, dtype=np.int16)
        energy = np.sqrt(np.sum(audio_data ** 2) / len(audio_data))
        return energy
    
    def _is_speech(self, audio_chunk):
        """Detect if chunk contains speech"""
        energy = self._get_audio_energy(audio_chunk)
        return energy > self.energy_threshold
    
    def record_until_silence(self):
        """Record audio until user stops speaking"""
        if not self.available:
            print("\nâœ— Audio recording not available (missing pyaudio or numpy)")
            return None
        
        print("\n" + "â•"*70)
        print("ğŸ¤ RECORDING - Speak now!")
        print("â•"*70)
        
        p = pyaudio.PyAudio()
        
        try:
            stream = p.open(
                format=pyaudio.paInt16,
                channels=1,
                rate=self.sample_rate,
                input=True,
                frames_per_buffer=self.chunk_size
            )
            
            frames = []
            silence_frames = 0
            frame_count = 0
            speech_started = False
            
            min_frames = int(Config.MIN_RECORDING_MS / self.chunk_duration_ms)
            max_frames = int(Config.MAX_RECORDING_SECONDS * 1000 / self.chunk_duration_ms)
            
            while frame_count < max_frames:
                try:
                    chunk = stream.read(self.chunk_size, exception_on_overflow=False)
                except Exception as e:
                    print(f"\nâœ— Audio error: {e}")
                    break
                
                frame_count += 1
                frames.append(chunk)
                
                is_speech = self._is_speech(chunk)
                energy = self._get_audio_energy(chunk)
                
                if is_speech:
                    speech_started = True
                    silence_frames = 0
                    print(f"ğŸ”´ Recording... [{frame_count} frames] Energy: {energy:6.0f} ğŸ”Š", end="\r")
                else:
                    if speech_started:
                        silence_frames += 1
                        print(f"â¸ï¸  Silence detected... [{silence_frames}/{self.silence_threshold}]  ", end="\r")
                        
                        # Stop if enough silence
                        if silence_frames > self.silence_threshold and frame_count >= min_frames:
                            print("\nâœ“ Recording complete!")
                            break
                    else:
                        print(f"âšª Waiting for speech... (Energy: {energy:6.0f})     ", end="\r")
            
            stream.stop_stream()
            stream.close()
            
            if len(frames) == 0:
                print("\nâœ— No audio recorded")
                return None
            
            # Save audio
            self._save_audio(frames, Config.TEMP_AUDIO)
            
            duration = len(frames) * self.chunk_duration_ms / 1000
            print(f"âœ“ Duration: {duration:.2f}s | Frames: {len(frames)}")
            print("â•"*70 + "\n")
            
            return Config.TEMP_AUDIO
            
        except KeyboardInterrupt:
            print("\n\nâ¹ï¸  Recording stopped by user\n")
            return None
        finally:
            p.terminate()
    
    def _save_audio(self, frames, filename):
        """Save recorded frames to WAV file"""
        with wave.open(filename, 'wb') as wav_file:
            wav_file.setnchannels(1)
            wav_file.setsampwidth(2)
            wav_file.setframerate(self.sample_rate)
            wav_file.writeframes(b''.join(frames))


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#                     SPEECH-TO-TEXT (WHISPER)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class SpeechToText:
    """Fast and accurate speech transcription using Whisper"""
    
    def __init__(self):
        if not STT_AVAILABLE:
            self.model = None
            return
        
        try:
            print("â³ Loading Whisper model...")
            self.model = WhisperModel(
                Config.WHISPER_MODEL,
                device="cpu",
                compute_type="int8",
                num_workers=4
            )
            print(f"âœ“ Whisper model loaded: {Config.WHISPER_MODEL}")
        except Exception as e:
            print(f"âœ— Failed to load Whisper: {e}")
            self.model = None
    
    def transcribe(self, audio_path):
        """Convert audio to text"""
        if not self.model:
            return None, "STT not available"
        
        try:
            print("ğŸ§ Transcribing audio...")
            start_time = time.time()
            
            segments, info = self.model.transcribe(
                audio_path,
                beam_size=Config.WHISPER_BEAM_SIZE,
                vad_filter=True,
                vad_parameters=dict(
                    min_silence_duration_ms=500,
                    threshold=0.5
                ),
                condition_on_previous_text=True,
                temperature=0.0
            )
            
            text = ""
            for segment in segments:
                text += segment.text + " "
            
            text = text.strip()
            elapsed = time.time() - start_time
            
            print(f"âœ“ Transcribed in {elapsed:.2f}s: '{text[:60]}...'")
            return text, None
            
        except Exception as e:
            return None, f"Transcription error: {str(e)}"


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#                      TEXT-TO-SPEECH (PIPER)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class TextToSpeech:
    """Natural voice synthesis using Piper"""
    
    def __init__(self):
        self.piper_exe = Config.PIPER_EXE
        self.piper_voice = Config.PIPER_VOICE
        self.available = os.path.exists(self.piper_exe) and os.path.exists(self.piper_voice)
        
        if self.available:
            print(f"âœ“ TTS available: {Path(self.piper_voice).name}")
        else:
            print("âš  TTS not available - Piper not found")
    
    def synthesize(self, text, output_file=None):
        """Convert text to speech audio file"""
        if not self.available:
            return None, "TTS not available"
        
        if output_file is None:
            output_file = Config.RESPONSE_AUDIO
        
        try:
            # Remove old file
            if os.path.exists(output_file):
                try:
                    os.remove(output_file)
                except:
                    pass
            
            print("ğŸ—£ï¸  Synthesizing speech...")
            start_time = time.time()
            
            result = subprocess.run([
                self.piper_exe,
                "--model", self.piper_voice,
                "--output_file", output_file
            ], input=text.encode(), capture_output=True, timeout=30)
            
            elapsed = time.time() - start_time
            
            if result.returncode == 0 and os.path.exists(output_file):
                print(f"âœ“ Speech synthesized in {elapsed:.2f}s")
                return output_file, None
            else:
                error = result.stderr.decode() if result.stderr else "Unknown error"
                return None, f"TTS error: {error}"
                
        except subprocess.TimeoutExpired:
            return None, "TTS timeout"
        except Exception as e:
            return None, f"TTS error: {str(e)}"
    
    def play_audio(self, audio_file):
        """Play audio file using Windows native playback"""
        if not os.path.exists(audio_file):
            print(f"âš  Audio file not found: {audio_file}")
            return False
        
        try:
            print(f"ğŸ”Š Playing audio...")
            if AUDIO_PLAYBACK:
                winsound.PlaySound(str(audio_file), winsound.SND_FILENAME)
            else:
                os.startfile(audio_file)
            return True
        except Exception as e:
            print(f"âš  Could not play audio: {e}")
            return False


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#                    CONVERSATION MEMORY MANAGER
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class ConversationMemory:
    """Persistent conversation history with automatic saving"""
    
    def __init__(self):
        self.history = []
        self.max_history = Config.MAX_HISTORY
        self.memory_file = Config.MEMORY_FILE
        self.load()
    
    def load(self):
        """Load conversation history from file"""
        if os.path.exists(self.memory_file):
            try:
                with open(self.memory_file, 'r', encoding='utf-8') as f:
                    self.history = json.load(f)
                print(f"âœ“ Loaded {len(self.history)} messages from memory")
            except Exception as e:
                print(f"âš  Could not load memory: {e}")
                self.history = []
        else:
            self.history = []
    
    def save(self):
        """Save conversation history to file"""
        try:
            with open(self.memory_file, 'w', encoding='utf-8') as f:
                json.dump(self.history, f, indent=2, ensure_ascii=False)
        except Exception as e:
            print(f"âš  Could not save memory: {e}")
    
    def add_user_message(self, text):
        """Add user message to history"""
        self.history.append({
            "role": "user",
            "content": text,
            "timestamp": datetime.now().isoformat()
        })
        self._trim_history()
        self.save()
    
    def add_assistant_message(self, text):
        """Add assistant message to history"""
        self.history.append({
            "role": "assistant",
            "content": text,
            "timestamp": datetime.now().isoformat()
        })
        self._trim_history()
        self.save()
    
    def _trim_history(self):
        """Keep only recent messages"""
        if len(self.history) > self.max_history:
            self.history = self.history[-self.max_history:]
    
    def build_prompt(self):
        """Build conversation prompt for LLM"""
        prompt = ""
        for msg in self.history:
            prompt += f"{msg['role']}: {msg['content']}\n"
        prompt += "assistant:"
        return prompt
    
    def clear(self):
        """Clear all conversation history"""
        self.history = []
        self.save()
    
    def get_summary(self):
        """Get conversation summary"""
        if not self.history:
            return "No conversation history"
        
        summary = f"Conversation History ({len(self.history)} messages):\n"
        summary += "â”€"*70 + "\n"
        for msg in self.history[-10:]:  # Show last 10
            role = "You" if msg["role"] == "user" else "JUNO"
            content = msg["content"][:60] + "..." if len(msg["content"]) > 60 else msg["content"]
            summary += f"{role}: {content}\n"
        return summary


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#                         AI BRAIN (LLM INTEGRATION)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class AIBrain:
    """AI reasoning and response generation using Ollama"""
    
    def __init__(self):
        self.ollama_url = Config.OLLAMA_URL
        self.model = Config.OLLAMA_MODEL
        self.check_connection()
    
    def check_connection(self):
        """Check if Ollama is running"""
        if not REQUESTS_AVAILABLE:
            print("âš  requests library not available - cannot check Ollama")
            return False
        
        try:
            response = requests.get("http://localhost:11434/api/tags", timeout=2)
            if response.status_code == 200:
                print(f"âœ“ Ollama connected: {self.model}")
                return True
        except:
            pass
        print("âš  Ollama not connected - voice chat will not work")
        print("  Start Ollama: ollama serve")
        return False
    
    def generate_response(self, prompt):
        """Generate AI response"""
        if not REQUESTS_AVAILABLE:
            return None, "requests library not available"
        
        try:
            print("ğŸ§  Thinking...")
            start_time = time.time()
            
            response = requests.post(
                self.ollama_url,
                json={
                    "model": self.model,
                    "prompt": prompt,
                    "stream": False,
                    "options": {
                        "num_predict": Config.MAX_TOKENS,
                        "temperature": 0.7,
                        "top_k": 40,
                        "top_p": 0.9,
                        "num_ctx": 2048
                    }
                },
                timeout=30
            )
            
            elapsed = time.time() - start_time
            
            if response.status_code == 200:
                reply = response.json()["response"]
                print(f"âœ“ Response generated in {elapsed:.2f}s")
                return reply, None
            else:
                return None, f"LLM Error: {response.status_code}"
                
        except requests.exceptions.Timeout:
            return None, "LLM timeout (model may be loading, try again)"
        except requests.exceptions.ConnectionError:
            return None, "Cannot connect to Ollama. Start it with: ollama serve"
        except Exception as e:
            return None, f"LLM Error: {str(e)}"
    
    def process_command(self, text):
        """Check if text is a system command"""
        text_lower = text.lower().strip()
        
        # Time commands
        if any(word in text_lower for word in ["time", "clock", "what time"]):
            current_time = datetime.now().strftime("%I:%M %p")
            return True, f"The current time is {current_time}"
        
        # Date commands
        if any(word in text_lower for word in ["date", "today", "what day"]):
            current_date = datetime.now().strftime("%B %d, %Y")
            return True, f"Today is {current_date}"
        
        # Clear memory
        if "clear memory" in text_lower or "forget everything" in text_lower:
            return True, "CLEAR_MEMORY"
        
        return False, None


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#                      MAIN VOICE ASSISTANT
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class JunoVoiceAssistant:
    """Complete voice assistant orchestrator"""
    
    def __init__(self):
        print("\n" + "â•"*70)
        print("  ğŸš€ INITIALIZING JUNO - AI VOICE ASSISTANT")
        print("â•"*70 + "\n")
        
        self.recorder = AudioRecorder()
        self.stt = SpeechToText()
        self.tts = TextToSpeech()
        self.memory = ConversationMemory()
        self.brain = AIBrain()
        self.conversation_count = 0
        
        print("\n" + "â•"*70)
        print("  âœ“ JUNO READY FOR VOICE INTERACTION")
        print("â•"*70 + "\n")
    
    def voice_chat_turn(self):
        """Execute one complete voice interaction turn"""
        
        # Check if recording is available
        if not self.recorder.available:
            print("\nâœ— Cannot record audio - pyaudio or numpy not installed")
            print("  Install: pip install pyaudio numpy")
            return False
        
        # Step 1: Record audio
        audio_file = self.recorder.record_until_silence()
        if not audio_file:
            return False
        
        # Step 2: Transcribe
        user_text, stt_error = self.stt.transcribe(audio_file)
        if stt_error or not user_text:
            print(f"âœ— {stt_error or 'No speech detected'}")
            return True
        
        print(f"\nğŸ“ You said: \"{user_text}\"")
        
        # Check for exit commands
        if any(word in user_text.lower() for word in ["exit", "quit", "goodbye", "bye bye"]):
            print("\nğŸ‘‹ Goodbye! See you next time!")
            return False
        
        # Step 3: Check for system commands
        is_command, command_result = self.brain.process_command(user_text)
        
        if is_command:
            if command_result == "CLEAR_MEMORY":
                self.memory.clear()
                reply = "Memory cleared. Starting fresh conversation."
                print(f"ğŸ¤– JUNO: {reply}")
            else:
                reply = command_result
                print(f"ğŸ¤– JUNO: {reply}")
        else:
            # Step 4: Add to memory and generate AI response
            self.memory.add_user_message(user_text)
            prompt = self.memory.build_prompt()
            
            reply, error = self.brain.generate_response(prompt)
            if error:
                print(f"âœ— {error}")
                return True
            
            self.memory.add_assistant_message(reply)
            print(f"ğŸ¤– JUNO: {reply}")
        
        # Step 5: Synthesize and play response
        audio_file, tts_error = self.tts.synthesize(reply)
        if not tts_error and audio_file:
            self.tts.play_audio(audio_file)
        
        self.conversation_count += 1
        print(f"\n{'â”€'*70}")
        print(f"âœ“ Turn {self.conversation_count} complete")
        print("â”€"*70 + "\n")
        
        # Cleanup
        if os.path.exists(Config.TEMP_AUDIO):
            try:
                os.remove(Config.TEMP_AUDIO)
            except:
                pass
        
        return True
    
    def interactive_mode(self):
        """Run continuous interactive voice chat"""
        print("\n" + "â•"*70)
        print("  ğŸ¤ INTERACTIVE VOICE CHAT MODE")
        print("â•"*70)
        print("\n  Talk naturally. JUNO will respond with voice.")
        print("  Say 'exit', 'quit', or 'goodbye' to end.")
        print("  Press Ctrl+C to stop anytime.")
        print("\n" + "â•"*70 + "\n")
        
        try:
            while True:
                continue_chat = self.voice_chat_turn()
                if not continue_chat:
                    break
        except KeyboardInterrupt:
            print("\n\nâ¹ï¸  Voice chat stopped by user\n")
        
        print(f"\nâœ“ Session complete: {self.conversation_count} turns")
        print(self.memory.get_summary())
    
    def show_menu(self):
        """Show interactive menu"""
        print("\n" + "â•"*70)
        print("  JUNO - MAIN MENU")
        print("â•"*70)
        print("\n  1. ğŸ¤ Interactive Voice Chat (continuous)")
        print("  2. ğŸ“ Single Voice Query")
        print("  3. ğŸ“œ View Conversation History")
        print("  4. ğŸ—‘ï¸  Clear Memory")
        print("  5. âŒ Exit")
        print("\n" + "â•"*70)
        
        choice = input("\n  Select option (1-5): ").strip()
        return choice
    
    def single_query(self):
        """Process a single voice query"""
        print("\n" + "â•"*70)
        print("  ğŸ¤ SINGLE VOICE QUERY MODE")
        print("â•"*70 + "\n")
        
        self.voice_chat_turn()
    
    def show_history(self):
        """Display conversation history"""
        print("\n" + "â•"*70)
        print(self.memory.get_summary())
        print("â•"*70)
        input("\nPress Enter to continue...")
    
    def run(self):
        """Main application loop"""
        while True:
            choice = self.show_menu()
            
            if choice == "1":
                self.interactive_mode()
            elif choice == "2":
                self.single_query()
            elif choice == "3":
                self.show_history()
            elif choice == "4":
                self.memory.clear()
                print("\nâœ“ Memory cleared!")
                input("Press Enter to continue...")
            elif choice == "5":
                print("\nğŸ‘‹ Goodbye!\n")
                break
            else:
                print("\nâœ— Invalid choice. Try again.")


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#                            MAIN ENTRY POINT
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def print_banner():
    """Display welcome banner"""
    print("\n")
    print("â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—")
    print("â•‘                                                                       â•‘")
    print("â•‘        â–ˆâ–ˆâ•—â–ˆâ–ˆâ•—   â–ˆâ–ˆâ•—â–ˆâ–ˆâ–ˆâ•—   â–ˆâ–ˆâ•— â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•—                                â•‘")
    print("â•‘        â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘â–ˆâ–ˆâ–ˆâ–ˆâ•—  â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â•â•â•â–ˆâ–ˆâ•—                               â•‘")
    print("â•‘        â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•”â–ˆâ–ˆâ•— â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘                               â•‘")
    print("â•‘   â–ˆâ–ˆ   â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘â•šâ–ˆâ–ˆâ•—â–ˆâ–ˆâ•‘â–ˆâ–ˆâ•‘   â–ˆâ–ˆâ•‘                               â•‘")
    print("â•‘   â•šâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•â•šâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•â–ˆâ–ˆâ•‘ â•šâ–ˆâ–ˆâ–ˆâ–ˆâ•‘â•šâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ•”â•                               â•‘")
    print("â•‘    â•šâ•â•â•â•â•  â•šâ•â•â•â•â•â• â•šâ•â•  â•šâ•â•â•â• â•šâ•â•â•â•â•â•                                â•‘")
    print("â•‘                                                                       â•‘")
    print("â•‘              Complete AI Voice Assistant - All-in-One                â•‘")
    print("â•‘                                                                       â•‘")
    print("â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•")
    print()


def check_dependencies():
    """Check and report system dependencies"""
    print("ğŸ” Checking system dependencies...\n")
    
    all_good = True
    
    # Check PyAudio
    if PYAUDIO_AVAILABLE:
        print("  âœ“ PyAudio installed")
    else:
        print("  âœ— PyAudio NOT installed - Required for recording")
        print("    Install: pip install pyaudio")
        all_good = False
    
    # Check NumPy
    if NUMPY_AVAILABLE:
        print("  âœ“ NumPy installed")
    else:
        print("  âœ— NumPy NOT installed")
        print("    Install: pip install numpy")
        all_good = False
    
    # Check faster-whisper
    if STT_AVAILABLE:
        print("  âœ“ faster-whisper installed")
    else:
        print("  âœ— faster-whisper NOT installed - Required for speech recognition")
        print("    Install: pip install faster-whisper")
        all_good = False
    
    # Check Piper
    if os.path.exists(Config.PIPER_EXE):
        print(f"  âœ“ Piper found: {Config.PIPER_EXE}")
    else:
        print(f"  âœ— Piper NOT found: {Config.PIPER_EXE}")
        print("    Download from: https://github.com/rhasspy/piper/releases")
        all_good = False
    
    # Check Piper voice
    if os.path.exists(Config.PIPER_VOICE):
        print(f"  âœ“ Voice model found: {Path(Config.PIPER_VOICE).name}")
    else:
        print(f"  âœ— Voice model NOT found: {Config.PIPER_VOICE}")
        all_good = False
    
    # Check requests
    if REQUESTS_AVAILABLE:
        print("  âœ“ requests installed")
    else:
        print("  âœ— requests NOT installed")
        print("    Install: pip install requests")
        all_good = False
    
    print()
    
    if not all_good:
        print("âš  WARNING: Some dependencies are missing!")
        print("  JUNO may not work properly.\n")
        response = input("Continue anyway? (y/n): ").lower()
        if response != 'y':
            print("\nâŒ Exiting. Please install missing dependencies.\n")
            sys.exit(1)
    else:
        print("âœ“ All dependencies satisfied!\n")
    
    return all_good


def main():
    """Main application entry point"""
    print_banner()
    
    # Check dependencies
    if not check_dependencies():
        print("\nâš  Running with missing dependencies...\n")
    
    # Create and run assistant
    try:
        assistant = JunoVoiceAssistant()
        assistant.run()
    except KeyboardInterrupt:
        print("\n\nâ¹ï¸  JUNO stopped by user. Goodbye! ğŸ‘‹\n")
    except Exception as e:
        print(f"\nâœ— Fatal error: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()
